{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ACxKFixuZtJ5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#imports\n",
    "from numpy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akqzvpG3mVnG"
   },
   "outputs": [],
   "source": [
    "# download the data file\n",
    "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1c0JAPxRLg9WzreUFzSYDqc2oHMK-AcPF' -O 'data.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsPUmSWdZ3ws"
   },
   "source": [
    "Linear Regression is an AI algorithm used for predicting one continuous variable from another. But what is a continuous variable? A continuous variable is one that can take on any range of values. For example, if we wanted to store the amount of rain that fell on a day, we might get values of 0mm, 0.1mm, 2.9m or 3.7563792mm. On the other hand, if we wanted a variable to store the day of the week there would only be 7 possible values the variable could take on making it a categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pTUt0MmrauIV"
   },
   "source": [
    "So how do we predict one variable from another? We can use some mathematical constructs that we already know. We'll use the familiar concept of a function of the form, $y=f(x)=mx+c$, which you may recognise is the equation of a line. In our function, $x$ is the variable we know, or the 'feature' of the data and $y$ is the variable we are trying to predict, or 'target' using our $model$, $f(x)$.\n",
    "\n",
    "A simple problem solvable by linear regression is shown below, where the feature is 'hours slept' and the target to be predicted by the model is 'grumpiness'. Looking at the data we see that the points are scattered around a line. If we can figure out the equation for the line, we can use it as a model to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M0mrQlrutzxl"
   },
   "source": [
    "![regression1a-1.png](data:image/png;base64,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)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riWStzwSb7cn"
   },
   "source": [
    "To figure out how to find the parameters of the model we'll look at a problem where we try and predict test scores according to the amount of hours studied.\n",
    "\n",
    "The particular model that we looked at is parameterised by two variables $m$ and $c$. To come up with a model that accurately predicts test scores from hours studied we need to figure out what the values for these parameters are going to be.\n",
    "\n",
    "For this, we need a dataset which contains data someone might have collected from a number of students. The dataset would contain data points for every student with the amount of hours they studied $(x)$ and their test score $(y)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AnrPmotdFqC"
   },
   "source": [
    "To explore the dataset, we'll load in the data and check how many data points we have in our dataset. Also, we'll display the first 10 points in the dataset to check if we can observe any relationship between the feature and the target.\n",
    "\n",
    "Before you run the next code block, what do you expect to see in the data? Would you expect the test scores $(y)$ to be lower for a higher amount of hours studied $(x)$, or the other way around?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y-yRhMq_ZyGI"
   },
   "outputs": [],
   "source": [
    "# This code block loads the dataset into our program and displays some datapoints\n",
    "# You don't need to worry about how it works\n",
    "PATH = 'data.csv'\n",
    "\n",
    "points = genfromtxt(PATH, delimiter=',')\n",
    "\n",
    "#Extract columns\n",
    "x = np.array(points[:,0])\n",
    "y = np.array(points[:,1])\n",
    "\n",
    "print('Number of data points: ', x.shape[0])\n",
    "\n",
    "print(\"Data Point Number,   Num of Hours Studied (x),     Test Scores (y)\")\n",
    "\n",
    "for i in range(10):\n",
    "  print( str(i) + \":                            \" + str(round(x[i], 2)) + \"                     \" + str(round(y[i], 2)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQ0AJBahr5OQ"
   },
   "source": [
    "So it looks like we have a fairly small dataset of 100 points. Also a higher amount of hours studied lead to higher test scores in the 10 data points we looked at! But what about the rest of the 90 points. Instead of printing them on the screen let's plot the data on a graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9kw2UbenfcG"
   },
   "outputs": [],
   "source": [
    "# Plot the dataset on a graph using the Matplotlib third-party package\n",
    "# You don't need to worry about how this works\n",
    "fig1  = plt.figure()\n",
    "ax1   = fig1.gca()\n",
    "\n",
    "fig1.set_size_inches(15, 10)\n",
    "\n",
    "ax1.scatter(x, y, label='Data Points')\n",
    "ax1.set_xlabel('Hours of study')\n",
    "ax1.set_ylabel('Test scores')\n",
    "ax1.set_title('Dataset')\n",
    "ax1.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SiYoRYsZmxsf"
   },
   "source": [
    "So looking the plot we can identify that there is a positive correlation between the amount of hours studied and test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjXoGHvWxVYd"
   },
   "source": [
    "Coming back to our model, $y=mx+c$, we wanted to figure out some values for $m$ and $c$ such that when we substitute an $x$ for the amount of hours studied, our model will predict a test score $y$. Before we do try and learn the $m$ and $c$ parameters let's try to work out some rough values by hit and trial which are able to make accurate predictions close to the actual values in the dataset.\n",
    "\n",
    "You might notice that our model is simply the equation of a line with $m$ being the gradient of the line and $c$ the y-intercept. Try some values to draw a line that passes through the data points in the code segment below. We'll start with a random guess of $m=0.5$ and $c=0$.\n",
    "\n",
    "To make the graph a little easier to see, we'll use only the first 10 points of the data and come back to using the entire dataset later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-E5sU4Kg1C6V"
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "1.   Fill in the 'predict' function so that it implements the mathematical function, $y=mx+c$\n",
    "\n",
    "2.   Try changing the values of $m$ and $c$ and re-running the code block till the line is reasonably close to passing through the data. The graph is displayed when you run this code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EgcCOyPGy2O8"
   },
   "outputs": [],
   "source": [
    "# Exercise: Try changing the values for m and c below so that the line passes through the data\n",
    "m = 0.5\n",
    "c = 0\n",
    "\n",
    "num_points = 10\n",
    "\n",
    "# Exercise: Fill in this function to implement y=mx+c and return the y variable\n",
    "def predict(x, m, c):\n",
    "  # Insert your code here and comment the line below by adding a '#' symbol at the start of the line. Or you could also, just delete it!\n",
    "  raise NotImplementedError\n",
    "\n",
    "# NO CHANGES REQUIRED BELOW\n",
    "\n",
    "# This function plots the line and the data points on the graph, no need to change anything in here\n",
    "def plot_line_and_data(x, y, m, c):\n",
    "  x_line  = np.linspace(20, 80, 100)\n",
    "  y_line  = predict(x_line, m, c)\n",
    "\n",
    "  # Values to try and predict\n",
    "  x_vals = x[:num_points]\n",
    "  x_vals = np.array(x_vals)\n",
    "\n",
    "  y_vals  = predict(x_vals, m, c)\n",
    "\n",
    "  # Plot the dataset\n",
    "  fig2  = plt.figure()\n",
    "  ax2   = fig2.gca()\n",
    "\n",
    "  fig2.set_size_inches(15, 10)\n",
    "\n",
    "  ax2.plot( x_line, y_line, color='r', label='Predictions Line' )\n",
    "  ax2.scatter( x_vals, y_vals, color='g', marker='x', s=200, label='Predicted Points' )\n",
    "  ax2.scatter( x[:num_points], y[:num_points], s=200, label='Data Points' )\n",
    "  ax2.set_xlabel('Hours of study')\n",
    "  ax2.set_ylabel('Test scores')\n",
    "  ax2.legend()\n",
    "\n",
    "  plt.show( )\n",
    "\n",
    "plot_line_and_data(x, y, m, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn0ugxnq0Zwi"
   },
   "source": [
    "So we were able to figure out some rough values for our parameters such that our models predictions were close to the actual values. You might have found this difficult to do visually.\n",
    "\n",
    "In practice, we try to minimise a loss function or error function to get accurate values for our parameters. For linear regression, we use a function called the mean square error loss given below.\n",
    "\n",
    "Mean Squared Error, $ l = \\frac{1}{N} \\sum^N_{i=0} [\\hat{y}_i - y_i]^2 = \\frac{1}{N} \\sum^N_{i=0} [(m*x_i+c) - y_i] ^2$\n",
    "\n",
    "While this may look complicated the equation is actually quite simple. The MSE function uses the model to predict the targets $(y_i)$ for every point $(x_i)$ in the dataset. It then measures the difference between the prediction $(\\hat y_i)$ and the target $(y_i)$ and squares it to get a measurement of the error between the predictions and the true targets. Finally, it sums up the error for all the $N$ points in the dataset before taking an average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ykTjH_J4BIF"
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "\n",
    "1.   Fill in the 'mse_loss' function below to implement the mathematical function shown above and return the loss\n",
    "2.   Try different values of $m$ and $c$ to minimise the MSE loss as much as you can. The MSE loss is displayed when you run the code block\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRBHbeaeGojl"
   },
   "outputs": [],
   "source": [
    "# Exercise: Try changing the values for m and c below to get the MSE loss as low as you can\n",
    "m = 0.5\n",
    "c = 0\n",
    "\n",
    "# Exercise: Fill in this function to calculate and return the mean squared error loss as shown in the function above\n",
    "def mse_loss(y_pred, y):\n",
    "  # Insert your code here and comment the line below by adding a '#' symbol at the start of the line. Or you could also, just delete it!\n",
    "  raise NotImplementedError\n",
    "\n",
    "# NO CHANGES REQUIRED BELOW\n",
    "\n",
    "# This function plots the line, data and error, This doesn't need to be changed\n",
    "def plot_line_and_data_and_error(x, y, m, c):\n",
    "  x_line  = np.linspace(20, 80, 100)\n",
    "  y_line  = predict(x_line, m, c)\n",
    "\n",
    "  # Values to try and predict, try adding some more values to the list of numbers below!\n",
    "  x_vals = x[:num_points]\n",
    "  x_vals = np.array(x_vals)\n",
    "\n",
    "  y_vals  = predict(x_vals, m, c)\n",
    "\n",
    "  # Plot the dataset\n",
    "  fig3  = plt.figure()\n",
    "  ax3   = fig3.gca()\n",
    "\n",
    "  fig3.set_size_inches(15, 10)\n",
    "\n",
    "  ax3.plot( x_line, y_line, color='r', label='Predictions Line' )\n",
    "  for i in range(num_points):\n",
    "    if i == 0:\n",
    "      ax3.plot( np.repeat(x_vals[i], 2), (y[i], y_vals[i]), ls='--', color='b', label='Error' )\n",
    "    ax3.plot( np.repeat(x_vals[i], 2), (y[i], y_vals[i]), color='b', ls='--' )\n",
    "  ax3.scatter( x_vals, y_vals, color='g', marker='x', s=200, label='Predicted Points' )\n",
    "  ax3.scatter( x[:num_points], y[:num_points], s=200, label='Data Points' )\n",
    "  ax3.set_xlabel('Hours of study')\n",
    "  ax3.set_ylabel('Test scores')\n",
    "  ax3.legend()\n",
    "\n",
    "  plt.show( )\n",
    "\n",
    "  loss = mse_loss(y_vals, y[:num_points])\n",
    "  print(\"\\n\\nMSE Loss: \", loss )\n",
    "\n",
    "plot_line_and_data_and_error(x, y, m, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMr_SYcyNIQF"
   },
   "source": [
    "At this point we've managed to minimise our MSE loss function by adjusting our models parameters through hit and trial. We'll now look at an AI algorithm that is able to learn these parameters automatically by looking at the dataset and iteratively correcting itself till it is able to achieve the minimal loss.\n",
    "\n",
    "The specific algorithm we'll look at is the Gradient Descent Algorithm that you studied in the lecture earlier today.\n",
    "\n",
    "Recall that the Gradient Descent algorithm is used to work out the values of our model parameters, $m$ and $c$ in this case, which minimise the loss function. \n",
    "\n",
    "By starting with an initial guess for the parameters we take small steps in the direction of the negative gradient as shown below in the gradient descent update equations to get a better estimate of the parameters.\n",
    "\n",
    "\n",
    "$$m_{i+1} = m_i - \\gamma \\frac{dl}{dm}$$\n",
    "\n",
    "$$c_{i+1} = c_i - \\gamma \\frac{dl}{dc}$$\n",
    "\n",
    "where,\n",
    "\n",
    "$$ l = \\frac{1}{N} \\sum^N_{i=0} [\\hat{y}_i - y_i]^2 = \\frac{1}{N} \\sum^N_{i=0} [(m*x_i+c) - y_i]^2 $$  is the MSE loss and $\\gamma$ is the learning rate.\n",
    "\n",
    "\n",
    "Notice that the above equations require finding and coding the partial derivatives, $\\frac{dl}{dm}$ and $\\frac{dl}{dc}$. Using some basic calculus, we can compute the derivative w.r.t '$m$' as shown below\n",
    "\n",
    "\n",
    "$$ \\frac{dl}{dm} = \\frac{d}{dm} \\{ \\frac{1}{N} \\sum^N_{i=0} [(mx_i+c) - y_i]^2\\}$$\n",
    "\n",
    "$$ \\frac{dl}{dm} = \\frac{1}{N} \\sum^N_{i=0} 2x_i * [ (mx_i+c) - y_i ] $$\n",
    "\n",
    "$$ \\frac{dl}{dm} = \\frac{2}{N} \\sum^N_{i=0} [ x_i * [ (mx_i+c) - y_i ] ] $$\n",
    "\n",
    "\n",
    "Similarly, the derivative w.r.t '$c$' can be calculated as \n",
    "\n",
    "\n",
    "$$ \\frac{dl}{dc} = \\frac{2}{N} \\sum^n_{i=0} [ [ (mx_i+c) - y_i ] ] $$\n",
    "\n",
    "Code these derivatives in the functions below and observe how the value of the MSE changes with every update made to the parameters. Use the given values of 10 and 0.0001 for the number of iterations and learning rate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4Facyef5JGY"
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "\n",
    "1.   Fill in the function 'm_grad' to compute and return the derivative of the MSE loss w.r.t $m$\n",
    "2.   Fill in the function 'c_grad' to compute and return the derivative of the MSE loss w.r.t $c$\n",
    "3.   Write code in the 'grad_descent_line' function to calculate the gradients from the 'm_grad' and 'c_grad' functions and store them in variables.\n",
    "4.   Write code in the 'grad_descent_line' function to implement the gradient descent update equations and update the values of $m$ and $c$ for the next iteration\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ax0Fl39AUEus"
   },
   "outputs": [],
   "source": [
    "num_iters     = 10\n",
    "learning_rate = 0.0001\n",
    "\n",
    "m = 0.5\n",
    "c = 0\n",
    "\n",
    "# Exercise: Fill in the function 'm_grad' to compute and return the derivative of the MSE loss w.r.t m\n",
    "def m_grad(x, m, c, y):\n",
    "  # Insert your code here and comment the line below by adding a '#' symbol at the start of the line. Or you could also, just delete it!\n",
    "  raise NotImplementedError\n",
    "\n",
    "# Exercise: Fill in the function 'm_grad' to compute and return the derivative of the MSE loss w.r.t c\n",
    "def c_grad(x, m, c, y):\n",
    "  # Insert your code here and comment the line below by adding a '#' symbol at the start of the line. Or you could also, just delete it!\n",
    "  raise NotImplementedError\n",
    "\n",
    "def grad_descent_line(x, y, m, c):\n",
    "\n",
    "  loss_hist = []\n",
    "\n",
    "  fig3  = plt.figure()\n",
    "  ax3   = fig3.gca()\n",
    "\n",
    "  fig3.set_size_inches(15, 10)\n",
    "\n",
    "  ax3.scatter( x, y, s=50, label='Data Points' )\n",
    "\n",
    "  for i in range(num_iters):\n",
    "\n",
    "    y_vals  = predict( x, m, c )\n",
    "\n",
    "    loss    = mse_loss(y_vals, y)\n",
    "    loss_hist.append(loss)\n",
    "\n",
    "    print( \"Iteration \" + str(i) + \" MSE Loss: \" + str(round(loss, 4)) + \"  (m, c): (\" + str(round(m, 2)) + \", \" + str(round(c, 2)) + \")\" )\n",
    "\n",
    "    num_lines_draw = 3\n",
    "\n",
    "    if (i % (num_iters//num_lines_draw)) == 0:\n",
    "      x_line  = np.linspace(20, 80, 100)\n",
    "      y_line  = predict(x_line, m, c)\n",
    "      ax3.plot( x_line, y_line, color='r', alpha = (i+1)/num_iters, label='Iteration '+str(i) )\n",
    "\n",
    "    # Exercise: Insert code here to calculate the gradients w.r.t 'm' and 'c' and store them in variables\n",
    "    # Exercise: Use the gradient descent update equation to update the values of the gradients\n",
    "    raise NotImplementedError\n",
    "\n",
    "  ax3.set_xlabel('Hours of study')\n",
    "  ax3.set_ylabel('Test scores')\n",
    "  ax3.legend()\n",
    "\n",
    "  fig4  = plt.figure()\n",
    "  ax4   = fig4.gca()\n",
    "\n",
    "  fig4.set_size_inches(15, 10)\n",
    "  ax4.plot(loss_hist, label='MSE Loss')\n",
    "  ax4.set_ylabel('MSE Loss')\n",
    "  ax4.set_xlabel('Iterations')\n",
    "  ax4.legend()\n",
    "\n",
    "  plt.show( )\n",
    "\n",
    "grad_descent_line(x, y, m, c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1mDOuoTfAR9"
   },
   "source": [
    "Now that we've trained the model on the dataset and learned the parameters to minimise we can use it to make predictions for test scores based on the hours of study!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Linear Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
